#!/usr/bin/env python3

import csv
import datetime
import gzip
import logging
import os
import pickle
import sys

import requests
  
from voter_reg_check.backends._lut import abbrev_us_state


states_across = True

base_url = "https://api.voteamerica.com/v1"
abbrevs = list(abbrev_us_state.keys())
election_info_fields = ["slug", "long_name", "field_format"]
today = datetime.datetime.now().strftime("%F")
data_fn = f"data/voteamerica-{today}.pkl.gz"
_logger = logging.getLogger(__name__)


def fetch_state_info(sa):
    _logger.info(f"Fetching data for {sa}")
    data = requests.get(base_url + "/election/state/" + sa).json()
    if "state_information" not in data:
        raise RuntimeError(f"state_information not in reply for {sa}")
    return {d["field_type"]: {"value": d["text"], "modified_at": d["modified_at"]}
            for d in data["state_information"]}


if __name__ == "__main__":
    logging.basicConfig(level="INFO")

    if os.path.exists(data_fn):
        all_data = pickle.load(gzip.open(data_fn, "rb"))
        _logger.info(f"Read data from {data_fn}")
    else:
        _logger.info(f"Fetching data for {today}")
        all_data = {sa: fetch_state_info(sa) for sa in abbrevs}
        pickle.dump(all_data, gzip.open(data_fn, "wb"))
        _logger.info(f"Wrote data to {data_fn}")
    

    fields = requests.get(base_url + "/election/field").json()
    fields = [f for f in fields if "phased out" not in f["long_name"]]
    slugs = [f["slug"] for f in fields]

    if states_across:
        tsv_out = csv.DictWriter(sys.stdout, delimiter="\t", fieldnames=election_info_fields + abbrevs)
        tsv_out.writeheader()
        for f in fields:
            slug = f["slug"]
            row = {h: f[h] for h in election_info_fields}
            row.update({sa: all_data[sa][slug]["value"] for sa in all_data})
            tsv_out.writerow(row)
    else:
        tsv_out = csv.DictWriter(sys.stdout, delimiter="\t", fieldnames=["state"]+slugs)
        tsv_out.writeheader()
        for sa, state_info in all_data.items():
            row = {slug: state_info[slug]["value"] for slug in slugs}
            row["state"] = sa
            tsv_out.writerow(row)
